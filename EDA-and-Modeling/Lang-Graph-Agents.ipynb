{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Develop and test the Lang-graph agents as a standalone\n",
    "#### The purpose of this notebook is to build, test, and assess the lang-graph agents with dummy Google API results\n",
    "#### It also runs the politifact data.\n",
    "#### Author: Michael Denton\n",
    "#### Published Date: April 15, 2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "import operator\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import JsonOutputParser, StrOutputParser, CommaSeparatedListOutputParser\n",
    "from langchain_community.llms import Ollama\n",
    "from typing import TypedDict, Annotated, Sequence\n",
    "from langchain_core.messages import BaseMessage\n",
    "from langchain.tools import Tool\n",
    "from langchain_community.utilities import GoogleSearchAPIWrapper\n",
    "from langchain.agents import AgentType, initialize_agent, load_tools\n",
    "\n",
    "from typing import List\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "import json\n",
    "\n",
    "\n",
    "text = \"The economy has grown by 4 percent in the last year, and Joe Biden is the reason. Joe Biden has grown hundreds of thousands of jobs. Despite being 81 years old, Joe Biden is still doing amazing work.\"\n",
    "\n",
    "\n",
    "llm = Ollama(model=\"mistral-openorca\")\n",
    "\n",
    "\"\"\"\n",
    "From a large text entry, supports the extraction of claims from the text\n",
    "\"\"\"\n",
    "\n",
    "# llm = Ollama(model=\"llama2\")\n",
    "\n",
    "# Define the output parser\n",
    "string_parser = StrOutputParser()\n",
    "# json_parser = JsonOutputParser()\n",
    "list_parser = CommaSeparatedListOutputParser()\n",
    "\n",
    "claims_agent_messages = [\n",
    "    (\"system\", \"[INST]You are tasked with extracting the verifiable claims from the user query.\"),\n",
    "    (\"system\", \"Each claim should exist as a unique immutable string in a python list without any extras, like this:\\n['first claim, 'second claim', 'third claim']\\n\"),\n",
    "    (\"system\", \"The domain focus is politics.\"),\n",
    "    (\"system\", \"One statement per claim.\"),\n",
    "    (\"user\", \"The user query:\\n{input}\\n\"),\n",
    "    (\"system\", \"[/INST]\")\n",
    "]\n",
    "\n",
    "judge_agent_messages = [\n",
    "    (\"system\", \"[INST]You are tasked with judging whether the following claims are contained within the text.\"),\n",
    "    (\"system\", \"If these Claims, Facts, or Opinions are not in the original text, you will answer 'no'. If they are, answer 'yes'\"),\n",
    "    (\"system\", \"The claims are:\\n{extracted_claims}\\n\"),\n",
    "    (\"system\", \"These were claims from the following text:\\n{input}\\n\"),\n",
    "    (\"system\", \"Are the claims are contained within the text? Answer only 'yes' or 'no' with no other text.[/INST]\")\n",
    "]\n",
    "\n",
    "feedback_agent_messages = [\n",
    "    (\"system\", \"Agents have assessed text for verifiable claims\"),\n",
    "    (\"system\", \"A judge has compared these to the original text and decided that the extracted claims are not sufficient based on the original text.\"),\n",
    "    (\"system\", \"Given the analysis and the original text, provide instructions to improve the output.\"),\n",
    "    (\"user\", \"The verifiable claims are:\\n{extracted_claims}\\n\"),\n",
    "    (\"user\", \"The origin text is:\\n{input}\\n\"),\n",
    "    (\"user\", \"What changes should the agents implement?\"),\n",
    "]\n",
    "\n",
    "\n",
    "feedback_prompt = \"You have previously done this before, and a judge has suggested the following notes to improve your answer: {reinforcer_notes}\"\n",
    "\n",
    "\n",
    "# claims_agent = claims_agent_messages | llm | list_parser\n",
    "# judge_agent = judge_agent_messages | llm | list_parser\n",
    "\n",
    "# Define the agent state\n",
    "class AgentState(TypedDict):\n",
    "    input_text: str\n",
    "    claims_to_check: list[str]\n",
    "    baseline: bool\n",
    "    apiversion: int\n",
    "    reinforcer_notes: str\n",
    "    judge_output: str\n",
    "    iteration: int\n",
    "    max_iterations: int\n",
    "    final_output: list\n",
    "    responses: list\n",
    "\n",
    "def input(state):\n",
    "    input_text = state[\"input_text\"]\n",
    "    \n",
    "    return {\"input_text\": input_text}\n",
    "\n",
    "def is_one_sentence(state):\n",
    "    \"\"\"\n",
    "    Checks if one sentence, if it is output go to search.\n",
    "    Otherwise we'll parse out facts in each sentence\n",
    "    \"\"\"\n",
    "\n",
    "    input_text = state[\"input_text\"]\n",
    "    if (len([val for val in str(input_text).split('.') if val != '']) == 1):\n",
    "        return 'go_to_search'\n",
    "    return 'extract_claims_from_text'\n",
    "\n",
    "\n",
    "def extract_claims(state):\n",
    "    input_text = state[\"input_text\"]\n",
    "    if state.get(\"reinforcer_notes\"):\n",
    "        claims_agent_messages.append((\"system\", feedback_prompt))\n",
    "    reinforcer_notes = state.get(\"reinforcer_notes\", \"\")\n",
    "\n",
    "    claims_prompt = ChatPromptTemplate.from_messages(claims_agent_messages)\n",
    "    claims_agent = claims_prompt | llm | list_parser\n",
    "    response = claims_agent.invoke({\"input\": input_text, \"reinforcer_notes\": reinforcer_notes})\n",
    "    print(response)\n",
    "    # The format comes back as a list within a list\n",
    "    if 'list' in str(type(response)).lower():\n",
    "        \n",
    "        if len(response) == 1:\n",
    "            new_response = response[0]\n",
    "        else:\n",
    "            new_response = response\n",
    "\n",
    "        if 'list' in str(type(new_response)).lower():\n",
    "            if len(new_response) > 1:\n",
    "                formatted_responses = []\n",
    "                for val in new_response:\n",
    "                    val = val.replace('[','').replace(']','').replace('<|im_end|>','')\n",
    "                    if '\\n' in val:\n",
    "                        vals = val.split('\\n')\n",
    "                        formatted_responses = formatted_responses + vals\n",
    "                    else:\n",
    "                        formatted_responses.append(val)\n",
    "                response = formatted_responses\n",
    "            \n",
    "\n",
    "    return {\"claims_to_check\": response}\n",
    "\n",
    "def extract_judgement(state):\n",
    "    formatted_extraction = state.get(\"claims_to_check\")\n",
    "    input = state.get(\"input_text\")\n",
    "\n",
    "    judge_prompt = ChatPromptTemplate.from_messages(judge_agent_messages)\n",
    "    judge_agent = judge_prompt | llm | string_parser\n",
    "    verdict = judge_agent.invoke({\"input\": input, \"extracted_claims\": formatted_extraction})\n",
    "    print(verdict)\n",
    "    if 'yes' in str(verdict).lower():\n",
    "        verdict = 'yes'\n",
    "    else:\n",
    "        verdict = 'no'\n",
    "\n",
    "    return {\"judge_output\": verdict}\n",
    "\n",
    "def feedback_on_incorrect_extractions(state):\n",
    "    formatted_extraction = state.get(\"claims_to_check\")\n",
    "    input = state.get(\"input_text\")\n",
    "    instructor_prompt = ChatPromptTemplate.from_messages(feedback_agent_messages)\n",
    "    instructor_agent = instructor_prompt | llm | string_parser\n",
    "    instructions = instructor_agent.invoke({\"input\": input, \"extracted_claims\":formatted_extraction})\n",
    "    return {\"reinforcer_notes\": instructions}                                                   \n",
    "\n",
    "def judge_happy(state):\n",
    "    judges_verdict = state.get(\"judge_output\")\n",
    "    judges_verdict = judges_verdict.strip().replace(\"\\n\", \"\").lower()\n",
    "    if judges_verdict == 'yes':\n",
    "        return 'continue'\n",
    "    return 'feedback'\n",
    "\n",
    "\n",
    "def google_search_agent(state):\n",
    "    \"\"\"\n",
    "    AgentType\n",
    "    \"\"\"\n",
    "    claims_to_check = state[\"claims_to_check\"] \n",
    "\n",
    "    if 'list' not in str(type(claims_to_check)).lower():\n",
    "        claims_to_check = [claims_to_check]\n",
    "\n",
    "    responses = []\n",
    "    for clm in claims_to_check:\n",
    "        responses.append(google_search_agent_call(stuff=clm, llm=llm))\n",
    "\n",
    "    return {\"responses\": responses} \n",
    "\n",
    "def print_output(state):\n",
    "    responses = state.get(\"responses\")\n",
    "\n",
    "    return {\"final_output\": responses}\n",
    "\n",
    "graph = StateGraph(AgentState)\n",
    "\n",
    "# Define nodes in our graph\n",
    "\n",
    "graph.add_node(\"input\", input)\n",
    "graph.add_node(\"claims_agent\", extract_claims)\n",
    "graph.add_node(\"judge_agent\", extract_judgement)\n",
    "graph.add_node(\"feedback_agent\", feedback_on_incorrect_extractions)\n",
    "graph.add_node(\"search_agent\", google_search_agent)\n",
    "graph.add_node(\"output\", print_output)\n",
    "\n",
    "graph.add_conditional_edges(\n",
    "    \"input\", \n",
    "    is_one_sentence, \n",
    "    {\n",
    "        \"go_to_search\": \"search_agent\",\n",
    "        \"extract_claims_from_text\": \"claims_agent\"\n",
    "    }\n",
    ")\n",
    "graph.add_edge('claims_agent', 'judge_agent')\n",
    "graph.add_conditional_edges(\n",
    "    \"judge_agent\",\n",
    "    judge_happy,\n",
    "    {\n",
    "        \"feedback\": \"feedback_agent\",\n",
    "        \"continue\": \"search_agent\"\n",
    "    }\n",
    ")\n",
    "graph.add_edge('feedback_agent', 'claims_agent')\n",
    "graph.add_edge(\"search_agent\", \"output\")\n",
    "graph.add_edge('output', END)\n",
    "\n",
    "graph.set_entry_point(\"input\")\n",
    "\n",
    "verify = graph.compile()\n",
    "\n",
    "inputs = {\"input_text\": text}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        +-----------+                          \n",
      "                        | __start__ |                          \n",
      "                        +-----------+                          \n",
      "                              *                                \n",
      "                              *                                \n",
      "                              *                                \n",
      "                          +-------+                            \n",
      "                          | input |                            \n",
      "                          +-------+                            \n",
      "                              *                                \n",
      "                              *                                \n",
      "                              *                                \n",
      "                  +-----------------------+                    \n",
      "                  | input_is_one_sentence |                    \n",
      "                  +-----------------------+*                   \n",
      "                      ***                   *****              \n",
      "                    **                           *****         \n",
      "                  **                                  *****    \n",
      "       +--------------+                                    *** \n",
      "       | claims_agent |                                      * \n",
      "       +--------------+                                      * \n",
      "       ***            ***                                    * \n",
      "    ***                  **                                  * \n",
      "  **                       **                                * \n",
      "**                     +-------------+                       * \n",
      "*                      | judge_agent |                       * \n",
      "*                      +-------------+                       * \n",
      "*                             *                              * \n",
      "*                             *                              * \n",
      "*                             *                              * \n",
      "**               +-------------------------+                ** \n",
      "  **             | judge_agent_judge_happy |              **   \n",
      "    ***          +-------------------------+           ***     \n",
      "       ***            ***            ***            ***        \n",
      "          **        **                  **        **           \n",
      "            **    **                      **    **             \n",
      "      +----------------+              +--------------+         \n",
      "      | feedback_agent |              | search_agent |         \n",
      "      +----------------+              +--------------+         \n",
      "                                              *                \n",
      "                                              *                \n",
      "                                              *                \n",
      "                                         +--------+            \n",
      "                                         | output |            \n",
      "                                         +--------+            \n",
      "                                              *                \n",
      "                                              *                \n",
      "                                              *                \n",
      "                                        +---------+            \n",
      "                                        | __end__ |            \n",
      "                                        +---------+            \n"
     ]
    }
   ],
   "source": [
    "verify.get_graph().print_ascii()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_text': 'I am a single sentence.',\n",
      " 'claims_to_check': None,\n",
      " 'baseline': None,\n",
      " 'apiversion': None,\n",
      " 'reinforcer_notes': None,\n",
      " 'judge_output': None,\n",
      " 'iteration': None,\n",
      " 'max_iterations': None,\n",
      " 'final_output': [{'statement': None,\n",
      "                   'judgement': 'False',\n",
      "                   'justification': 'Dummy,',\n",
      "                   'process_time': None,\n",
      "                   'information': None,\n",
      "                   'message': 'Successfully returned judgement'}],\n",
      " 'responses': [{'statement': None,\n",
      "                'judgement': 'False',\n",
      "                'justification': 'Dummy,',\n",
      "                'process_time': None,\n",
      "                'information': None,\n",
      "                'message': 'Successfully returned judgement'}]}\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "out = verify.invoke({\"input_text\": \"I am a single sentence.\"})\n",
    "pprint.pp(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'statement': \"'Economy growth: 4 percent in the last year'\",\n",
      "  'judgement': 'False',\n",
      "  'justification': 'Dummy,',\n",
      "  'process_time': None,\n",
      "  'information': None,\n",
      "  'message': 'Successfully returned judgement'},\n",
      " {'statement': \"'Joe Biden: responsible for economic growth and job creation'\",\n",
      "  'judgement': 'False',\n",
      "  'justification': 'Dummy,',\n",
      "  'process_time': None,\n",
      "  'information': None,\n",
      "  'message': 'Successfully returned judgement'},\n",
      " {'statement': \"'Joe Biden: despite his age\",\n",
      "  'judgement': 'False',\n",
      "  'justification': 'Dummy,',\n",
      "  'process_time': None,\n",
      "  'information': None,\n",
      "  'message': 'Successfully returned judgement'},\n",
      " {'statement': \"doing amazing work'\",\n",
      "  'judgement': 'False',\n",
      "  'justification': 'Dummy,',\n",
      "  'process_time': None,\n",
      "  'information': None,\n",
      "  'message': 'Successfully returned judgement'}]\n"
     ]
    }
   ],
   "source": [
    "pprint.pp(out['final_output'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output from node 'input':\n",
      "---\n",
      "{'input_text': 'The economy has grown by 4 percent in the last year, and Joe Biden is the reason. Joe Biden has grown hundreds of thousands of jobs. Despite being 81 years old, Joe Biden is still doing amazing work.'}\n",
      "\n",
      "---\n",
      "\n",
      "Output from node 'claims_agent':\n",
      "---\n",
      "{'claims_to_check': ['1. The economy has grown by 4 percent in the last year.\\n2. Joe Biden is the reason for the economic growth.\\n3. Joe Biden has created hundreds of thousands of jobs.\\n4. Despite being 81 years old', 'Joe Biden is still doing amazing work.<|im_end|>']}\n",
      "\n",
      "---\n",
      "\n",
      " yes<|im_end|>\n",
      "Output from node 'judge_agent':\n",
      "---\n",
      "{'judge_output': 'yes'}\n",
      "\n",
      "---\n",
      "\n",
      "Output from node 'search_agent':\n",
      "---\n",
      "{'responses': [{'statement': '1. The economy has grown by 4 percent in the last year.\\n2. Joe Biden is the reason for the economic growth.\\n3. Joe Biden has created hundreds of thousands of jobs.\\n4. Despite being 81 years old', 'judgement': 'False', 'justification': 'Dummy,', 'process_time': None, 'information': None, 'message': 'Successfully returned judgement'}, {'statement': 'Joe Biden is still doing amazing work.<|im_end|>', 'judgement': 'False', 'justification': 'Dummy,', 'process_time': None, 'information': None, 'message': 'Successfully returned judgement'}]}\n",
      "\n",
      "---\n",
      "\n",
      "Output from node 'output':\n",
      "---\n",
      "{'final_output': [{'statement': '1. The economy has grown by 4 percent in the last year.\\n2. Joe Biden is the reason for the economic growth.\\n3. Joe Biden has created hundreds of thousands of jobs.\\n4. Despite being 81 years old', 'judgement': 'False', 'justification': 'Dummy,', 'process_time': None, 'information': None, 'message': 'Successfully returned judgement'}, {'statement': 'Joe Biden is still doing amazing work.<|im_end|>', 'judgement': 'False', 'justification': 'Dummy,', 'process_time': None, 'information': None, 'message': 'Successfully returned judgement'}]}\n",
      "\n",
      "---\n",
      "\n",
      "Output from node '__end__':\n",
      "---\n",
      "{'input_text': 'The economy has grown by 4 percent in the last year, and Joe Biden is the reason. Joe Biden has grown hundreds of thousands of jobs. Despite being 81 years old, Joe Biden is still doing amazing work.', 'claims_to_check': ['1. The economy has grown by 4 percent in the last year.\\n2. Joe Biden is the reason for the economic growth.\\n3. Joe Biden has created hundreds of thousands of jobs.\\n4. Despite being 81 years old', 'Joe Biden is still doing amazing work.<|im_end|>'], 'baseline': None, 'apiversion': None, 'reinforcer_notes': None, 'judge_output': 'yes', 'iteration': None, 'max_iterations': None, 'final_output': [{'statement': '1. The economy has grown by 4 percent in the last year.\\n2. Joe Biden is the reason for the economic growth.\\n3. Joe Biden has created hundreds of thousands of jobs.\\n4. Despite being 81 years old', 'judgement': 'False', 'justification': 'Dummy,', 'process_time': None, 'information': None, 'message': 'Successfully returned judgement'}, {'statement': 'Joe Biden is still doing amazing work.<|im_end|>', 'judgement': 'False', 'justification': 'Dummy,', 'process_time': None, 'information': None, 'message': 'Successfully returned judgement'}], 'responses': [{'statement': '1. The economy has grown by 4 percent in the last year.\\n2. Joe Biden is the reason for the economic growth.\\n3. Joe Biden has created hundreds of thousands of jobs.\\n4. Despite being 81 years old', 'judgement': 'False', 'justification': 'Dummy,', 'process_time': None, 'information': None, 'message': 'Successfully returned judgement'}, {'statement': 'Joe Biden is still doing amazing work.<|im_end|>', 'judgement': 'False', 'justification': 'Dummy,', 'process_time': None, 'information': None, 'message': 'Successfully returned judgement'}]}\n",
      "\n",
      "---\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "out = None\n",
    "for output in verify.stream(inputs):\n",
    "    # stream() yields dictionaries with output keyed by node name\n",
    "    for key, value in output.items():\n",
    "        print(f\"Output from node '{key}':\")\n",
    "        print(\"---\")\n",
    "        print(value)\n",
    "    print(\"\\n---\\n\")\n",
    "\n",
    "# for output in verify.stream(inputs):\n",
    "#     print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def google_search_agent_call(stuff=None, llm=None):\n",
    "\n",
    "    tmp = {\n",
    "        'statement': stuff,\n",
    "        'judgement': 'False',\n",
    "        'justification': 'Dummy,',\n",
    "        'process_time': None,\n",
    "        'information': None,\n",
    "        'message': 'Successfully returned judgement'\n",
    "    }\n",
    "\n",
    "    return tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "verifai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
